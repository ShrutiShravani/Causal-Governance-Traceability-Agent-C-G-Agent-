# ===============================================================
# POLICY REGISTRY — Maps each policy-as-code rule to:
# - OPA/Rego file
# - Description and enforcement context
# - Related EU AI Act article (or other regulation)
# - RAG reference for later text retrieval
# ===============================================================

# ===============================================================
# POLICY REGISTRY — Maps each policy-as-code rule to:
# - OPA/Rego file
# - Description and enforcement context
# - Related EU AI Act article (or other regulation)
# - RAG reference for later text retrieval
# ===============================================================

policies:
  prohibited_attribute_check:  # ← Use as KEY, not list item
    policy_name: "Prohibited Attribute Influence Check"
    version: "1.0"
    description: >
      Ensures that sensitive or protected attributes (e.g., SEX, AGE, EDUCATION)
      do not exert an excessive influence in local or global model explanations.
      Violations trigger a governance escalation or human review.
    rego_path: "v1/data/policies/prohibited_attrs"  # ← Fixed path to match your loaded policies
    enforcement_phase: "runtime"
    related_regulation:
      source: "EU AI Act"
      article: "Article 10 - Data and Data Governance"
      summary: >
        AI systems must ensure data quality and prevent bias based on
        protected attributes such as sex, age, or education.
    rag_reference:
      doc_id: "eu_ai_act_article_10"
      doc_path: "regulations/eu_ai_act_article_10.txt"
      vector_tag: "bias_mitigation"
    action_on_violation: "BLOCK"

  oversight_threshold_check:  # ← Use as KEY
    policy_name: "Confidence Threshold and Human Oversight"
    version: "1.0"
    description: >
      Enforces human oversight for low-confidence model predictions.
      Ensures compliance with EU AI Act Article 14 requiring
      transparency and human control.
    rego_path: "v1/data/policies/oversight_threshold"  # ← Fixed path
    enforcement_phase: "runtime"
    related_regulation:
      source: "EU AI Act"
      article: "Article 14 - Human Oversight"
      summary: >
        High-risk AI systems must allow effective human oversight when
        confidence is below a specified threshold.
    rag_reference:
      doc_id: "eu_ai_act_article_14"
      doc_path: "regulations/eu_ai_act_article_14.txt"
      vector_tag: "human_oversight"
    action_on_violation: "ESCALATE"
